{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32264997",
   "metadata": {},
   "source": [
    "# Colab Inference Demo\n",
    "\n",
    "This notebook downloads model weights and a zip of example images from your GitHub repo, runs inference on 3 random images and displays original + predicted mask. Edit the WEIGHTS_URL and IMAGES_ZIP_URL variables in the code cell below before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-ready inference demo (paste as a single code cell in Colab if you prefer)\n",
    "# Fetch model + example images from GitHub, run inference on 3 random images, show original + mask.\n",
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG â€” EDITA ESTES URLS\n",
    "# -----------------------\n",
    "WEIGHTS_URL = \"https://github.com/sequeiradiogo/Building-data-extraction/blob/main/models/unet_resnet34_epoch1_IoU0.7833.pth\"  # RAW link to your .pth in the repo or release\n",
    "IMAGES_ZIP_URL = \"https://github.com/sequeiradiogo/Building-data-extraction/blob/main/output/examples/test_images.zip\"  # RAW link to a zip with example images\n",
    "\n",
    "LOCAL_WEIGHTS_PATH = \"/content/unet_final.pth\"\n",
    "LOCAL_IMAGES_ZIP = \"/content/test_images.zip\"\n",
    "LOCAL_TEST_DIR = Path(\"/content/test_images\")\n",
    "\n",
    "MODEL_INPUT_SIZE = (512, 512)\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# -----------------------\n",
    "# Install dependencies\n",
    "# -----------------------\n",
    "!pip install -q segmentation-models-pytorch==0.3.0 torchvision torch opencv-python matplotlib pillow tqdm\n",
    "\n",
    "# -----------------------\n",
    "# Helper: simple file download\n",
    "# -----------------------\n",
    "def download(url, dest):\n",
    "    print(f\"Downloading: {url}\")\n",
    "    urllib.request.urlretrieve(url, dest)\n",
    "    print(\"Downloaded to:\", dest)\n",
    "\n",
    "# -----------------------\n",
    "# Download weights\n",
    "# -----------------------\n",
    "if WEIGHTS_URL == \"\":\n",
    "    raise ValueError(\"Paste the model URL.")\n",
    "\n",
    "download(WEIGHTS_URL, LOCAL_WEIGHTS_PATH)\n",
    "\n",
    "# -----------------------\n",
    "# Download example images (zip)\n",
    "# -----------------------\n",
    "if IMAGES_ZIP_URL == \"\":\n",
    "    raise ValueError(\"Paste the images URL\")\n",
    "\n",
    "download(IMAGES_ZIP_URL, LOCAL_IMAGES_ZIP)\n",
    "\n",
    "# unzip\n",
    "LOCAL_TEST_DIR.mkdir(exist_ok=True)\n",
    "with zipfile.ZipFile(LOCAL_IMAGES_ZIP, 'r') as z:\n",
    "    z.extractall(LOCAL_TEST_DIR)\n",
    "print(\"Extracted images to:\", LOCAL_TEST_DIR)\n",
    "\n",
    "# -----------------------\n",
    "# Load model\n",
    "# -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ")\n",
    "\n",
    "state = torch.load(LOCAL_WEIGHTS_PATH, map_location=device)\n",
    "model.load_state_dict(state, strict=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# -----------------------\n",
    "# Preprocess + visualization\n",
    "# -----------------------\n",
    "def preprocess_image_for_model(orig_img_rgb, input_size):\n",
    "    img = cv2.resize(orig_img_rgb, (input_size[1], input_size[0])).astype(np.float32) / 255.0\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "    img = (img - mean) / std\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    return torch.tensor(img).float().unsqueeze(0)\n",
    "\n",
    "def show_prediction(orig, mask, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(orig)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title('Predicted mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Select 3 random images & run inference\n",
    "# -----------------------\n",
    "files = sorted([p for p in LOCAL_TEST_DIR.iterdir() if p.suffix.lower() in ('.png','.jpg','.jpeg','.tif','.tiff')])\n",
    "if len(files) < 3:\n",
    "    raise ValueError(f'Need at least 3 images in {LOCAL_TEST_DIR}, found {len(files)}')\n",
    "\n",
    "sampled = random.sample(files, 3)\n",
    "print('Selected:', [p.name for p in sampled])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in sampled:\n",
    "        img_bgr = cv2.imread(str(p))\n",
    "        if img_bgr is None:\n",
    "            print('Warning: could not read', p)\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img_rgb.shape[:2]\n",
    "\n",
    "        inp = preprocess_image_for_model(img_rgb, MODEL_INPUT_SIZE).to(device)\n",
    "        logits = model(inp)\n",
    "        probs = torch.sigmoid(logits)[0,0].cpu().numpy()\n",
    "\n",
    "        mask_small = (probs > THRESHOLD).astype(np.uint8) * 255\n",
    "        mask = cv2.resize(mask_small, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        show_prediction(img_rgb, mask, title=p.name)\n",
    "\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
