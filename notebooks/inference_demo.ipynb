# ============================================
#   COLAB ONE-CLICK DEMO â€” CLEAN VERSION
#   Fetch model + example images from GitHub
#   Run inference on 3 random images
# ============================================

import os
import random
import urllib.request
from pathlib import Path

import cv2
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import segmentation_models_pytorch as smp

# -----------------------
#        CONFIG
# -----------------------

# RAW Model URL
WEIGHTS_URL = "https://github.com/sequeiradiogo/Building-data-extraction/blob/main/models/unet_resnet34_epoch1_IoU0.7833.pth"

# RAW Test URL
IMAGES_ZIP_URL = "https://github.com/sequeiradiogo/Building-data-extraction/blob/main/output/examples/test_images.zip"



LOCAL_WEIGHTS_PATH = "/content/unet_final.pth"
LOCAL_IMAGES_ZIP = "/content/test_images.zip"
LOCAL_TEST_DIR = Path("/content/test_images")

MODEL_INPUT_SIZE = (512, 512)
THRESHOLD = 0.5

# -----------------------
# Install dependencies
# -----------------------
!pip install -q segmentation-models-pytorch==0.3.0 torchvision torch opencv-python matplotlib pillow tqdm

# -----------------------
# Helper: simple file download
# -----------------------
def download(url, dest):
    print(f"Downloading: {url}")
    urllib.request.urlretrieve(url, dest)
    print("Downloaded to:", dest)

# -----------------------
# Download weights
# -----------------------

download(WEIGHTS_URL, LOCAL_WEIGHTS_PATH)

# -----------------------
# Download example images (zip)
# -----------------------

download(IMAGES_ZIP_URL, LOCAL_IMAGES_ZIP)

# unzip
import zipfile
LOCAL_TEST_DIR.mkdir(exist_ok=True)
with zipfile.ZipFile(LOCAL_IMAGES_ZIP, 'r') as z:
    z.extractall(LOCAL_TEST_DIR)
print("Extracted images to:", LOCAL_TEST_DIR)

# -----------------------
# Load model
# -----------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

model = smp.Unet(
    encoder_name="resnet34",
    encoder_weights=None,
    in_channels=3,
    classes=1,
)

state = torch.load(LOCAL_WEIGHTS_PATH, map_location=device)
model.load_state_dict(state, strict=False)

model.to(device)
model.eval()
print("Model loaded.")

# -----------------------
# Preprocess + visualization
# -----------------------
def preprocess_image_for_model(orig_img_rgb, input_size):
    img = cv2.resize(orig_img_rgb, (input_size[1], input_size[0])).astype(np.float32) / 255.0
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    img = (img - mean) / std
    img = img.transpose(2, 0, 1)
    return torch.tensor(img).float().unsqueeze(0)

def show_prediction(orig, mask, title):
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    plt.imshow(orig)
    plt.title(title)
    plt.axis("off")

    plt.subplot(1,2,2)
    plt.imshow(mask, cmap="gray")
    plt.title("Predicted Mask")
    plt.axis("off")

    plt.show()

# -----------------------
# Select 3 random images
# -----------------------
files = sorted([p for p in LOCAL_TEST_DIR.iterdir() if p.suffix.lower() in (".tif")])

if len(files) < 3:
    raise ValueError("Not enough images in the folder.")

sampled = random.sample(files, 3)
print("Selected:", [p.name for p in sampled])

# -----------------------
# Run inference
# -----------------------
with torch.no_grad():
    for p in sampled:
        img_bgr = cv2.imread(str(p))
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        h, w = img_rgb.shape[:2]

        inp = preprocess_image_for_model(img_rgb, MODEL_INPUT_SIZE).to(device)
        logits = model(inp)
        probs = torch.sigmoid(logits)[0,0].cpu().numpy()

        mask_small = (probs > THRESHOLD).astype(np.uint8) * 255
        mask = cv2.resize(mask_small, (w, h), interpolation=cv2.INTER_NEAREST)

        show_prediction(img_rgb, mask, title=p.name)

print("Done")
